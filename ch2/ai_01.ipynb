{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 12)\n",
      "(275, 1)\n",
      "(220, 12)\n",
      "(220, 1)\n",
      "(55, 12)\n",
      "(55, 1)\n"
     ]
    }
   ],
   "source": [
    "#### 데이터 로드\n",
    "df_ciminal = pd.read_csv('./data/pp_01_housingdata.csv')\n",
    "x_np = df_ciminal.iloc[:, :12].values\n",
    "x_np = (x_np - np.mean(x_np, axis=0)) / np.std(x_np, axis=0) # 표준화\n",
    "y_np = df_ciminal.iloc[:, 13].values.reshape(-1, 1)\n",
    "\n",
    "#### 셔플\n",
    "z = np.arange(x_np.shape[0])\n",
    "np.random.shuffle(z)\n",
    "x_np = x_np[z]\n",
    "y_np = y_np[z]\n",
    "\n",
    "print(x_np.shape)\n",
    "print(y_np.shape)\n",
    "\n",
    "\n",
    "#### train, test 분할\n",
    "cut_idx = int(len(x_np)*0.8)\n",
    "\n",
    "train_x  = x_np[:cut_idx]\n",
    "train_y  = y_np[:cut_idx]\n",
    "test_x  = x_np[cut_idx:]\n",
    "test_y  = y_np[cut_idx:]\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "#### 하이퍼 파라미터\n",
    "batch_size = 2\n",
    "learning_rate = 0.001\n",
    "num_epoch = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cvt_to_torch_dataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform = None):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "                \n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = cvt_to_torch_dataset(train_x, train_y)\n",
    "test_dataset = cvt_to_torch_dataset(test_x, test_y)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 256)  # input\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 16)\n",
    "        self.fc6 = nn.Linear(16, 8)\n",
    "        self.fc7 = nn.Linear(8, 1) # ouput\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 12)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss: 288.270\n",
      "[Epoch 6] loss: 13.442\n",
      "[Epoch 11] loss: 9.726\n",
      "[Epoch 16] loss: 8.147\n",
      "[Epoch 21] loss: 6.735\n",
      "[Epoch 26] loss: 5.464\n",
      "[Epoch 31] loss: 4.318\n",
      "[Epoch 36] loss: 5.497\n",
      "[Epoch 41] loss: 3.950\n",
      "[Epoch 46] loss: 4.699\n",
      "[Epoch 51] loss: 4.509\n",
      "[Epoch 56] loss: 3.264\n",
      "[Epoch 61] loss: 4.949\n",
      "[Epoch 66] loss: 3.323\n",
      "[Epoch 71] loss: 3.125\n",
      "[Epoch 76] loss: 3.064\n",
      "[Epoch 81] loss: 3.598\n",
      "[Epoch 86] loss: 2.554\n",
      "[Epoch 91] loss: 2.903\n",
      "[Epoch 96] loss: 1.996\n",
      "Finished Training\n",
      "batch_size : 2\n",
      "learning_rate : 0.001\n"
     ]
    }
   ],
   "source": [
    "#### 모델 초기화\n",
    "model = SimpleANN()\n",
    "\n",
    "#### 손실 함수와 최적화 알고리즘 정의\n",
    "loss_fn = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#### 모델 학습\n",
    "for epoch in range(num_epoch):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실 출력\n",
    "        running_loss += loss.item()\n",
    "        # if i % 1 == 0:  # 매 100 미니배치마다 출력\n",
    "        #     print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "        #     running_loss = 0.0\n",
    "            \n",
    "    if epoch % 5 == 0:\n",
    "        print(f'[Epoch {epoch + 1}] loss: {running_loss / 100:.3f}')\n",
    "\n",
    "print('Finished Training')\n",
    "print('batch_size :', batch_size)\n",
    "print('learning_rate :', learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_y : 55\n",
      "y_sum : 1258.300012588501\n",
      "y_mean : 22.878182047063653\n",
      "mean_loss :  6.65978\n",
      "loss_per :  0.2910974312461571\n"
     ]
    }
   ],
   "source": [
    "#### 평가\n",
    "count_y = 0\n",
    "y_sum = 0\n",
    "loss_list = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader: # 배치 단위 반복\n",
    "        x_data, y_data = data\n",
    "        outputs = model(x_data)\n",
    "        loss = loss_fn(outputs, y_data)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        #### \n",
    "        count_y += y_data.shape[0] # 개수\n",
    "        y_sum += y_data.numpy().sum() # y 총 합\n",
    "        \n",
    "\n",
    "loss_np = np.array(loss_list)\n",
    "mean_loss = loss_np.mean()\n",
    "y_mean = y_sum / count_y\n",
    "\n",
    "print('count_y :', count_y)\n",
    "print('y_sum :', y_sum)\n",
    "\n",
    "print('y_mean :', y_mean)\n",
    "print('mean_loss : ', mean_loss)\n",
    "print('loss_per : ', mean_loss / y_mean) # 오차율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 저장\n",
    "# torch.save(model.state_dict(), \"model.pth\")\n",
    "# print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "#### 로드\n",
    "# model = SimpleANN()\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3_12",
   "language": "python",
   "name": "python_3_12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
